TokenSheetData {
    tokens: [
        TokenData::Keyword(
            Keyword::Use,
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                Crate,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    ScopeResolution,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Star,
            ),
        ),
        TokenData::Keyword(
            Keyword::Use,
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                Crate,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    ScopeResolution,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Star,
            ),
        ),
        TokenData::Keyword(
            Keyword::Use,
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                Crate,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `convexity`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    ScopeResolution,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Star,
            ),
        ),
        TokenData::Keyword(
            Keyword::Use,
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                Crate,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `geom2d`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    ScopeResolution,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Star,
            ),
        ),
        TokenData::Keyword(
            Keyword::Use,
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                Crate,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    ScopeResolution,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Star,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::TypeEntity(
                Struct,
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Curl,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Tilde,
            ),
        ),
        TokenData::Ident(
            `LineSegmentSketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Tilde,
            ),
        ),
        TokenData::Ident(
            `CyclicSlice`,
        ),
        TokenData::Ident(
            `LineSegmentStroke`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Curl,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Impl,
        ),
        TokenData::Ident(
            `Visualize`,
        ),
        TokenData::Keyword(
            Keyword::Connection(
                For,
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `visualize`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `Visual`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `visualize`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Impl,
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Val,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `hausdorff_norm`,
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Val,
            ),
        ),
        TokenData::Ident(
            `rel_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    Closed(
                        Div,
                    ),
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Val,
            ),
        ),
        TokenData::Ident(
            `hausdorff_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `hausdorff_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Literal(
            LiteralData::Float(
                Unspecified(
                    UnspecifiedFloatLiteral(
                        Id {
                            value: 109,
                        },
                    ),
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `curve_start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `first`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `curve_ls`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `line_segment`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `dp_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `curve_ls`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                NonImplFor,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    Comparison(
                        Leq,
                    ),
                ),
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Box,
                ),
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `point_dist`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `curve_ls`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `dist_to_point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                If,
            ),
        ),
        TokenData::Ident(
            `point_dist`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Ident(
            `hausdorff_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `hausdorff_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `point_dist`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Return,
            ),
        ),
        TokenData::Ident(
            `hausdorff_norm`,
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Val,
            ),
        ),
        TokenData::Ident(
            `angle_change`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `angle_change`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Literal(
            LiteralData::Float(
                Unspecified(
                    UnspecifiedFloatLiteral(
                        Id {
                            value: 110,
                        },
                    ),
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `dp0`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                NonImplFor,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `dp`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Box,
                ),
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `angle_change`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    AssignClosed(
                        Add,
                    ),
                ),
            ),
        ),
        TokenData::Ident(
            `dp0`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `angle_to`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `dp`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Literal(
            LiteralData::Bool(
                True,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `dp0`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `dp`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Return,
            ),
        ),
        TokenData::Ident(
            `angle_change`,
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Val,
            ),
        ),
        TokenData::Ident(
            `bounding_box`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `BoundingBox`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `start_point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `first`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `xmin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `start_point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `x`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `xmax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `start_point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `x`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `ymin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `start_point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `y`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `ymax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `start_point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `y`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                NonImplFor,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    Comparison(
                        Leq,
                    ),
                ),
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Box,
                ),
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Ident(
            `xmin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `xmin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `min`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `x`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `xmax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `xmax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `max`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `x`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `ymin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `ymin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `min`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `y`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `ymax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `ymax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `max`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `y`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Return,
            ),
        ),
        TokenData::Ident(
            `BoundingBox`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `ClosedRange`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `xmin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `xmax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `ClosedRange`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `ymin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `ymax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Val,
            ),
        ),
        TokenData::Ident(
            `relative_bounding_box`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `RelativeBoundingBox`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `bounding_box`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `relative_bounding_box`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `bounding_box`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `line_segment`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `LineSegment`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `LineSegment`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `first`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `clone`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `last`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `clone`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `Point2d`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `first`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `clone`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `Point2d`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `last`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `clone`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `Vector2d`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `line_segment`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `start_tangent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `Vector2d`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `first`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `end_tangent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `Vector2d`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `last`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `find_concave_components`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Tilde,
            ),
        ),
        TokenData::Ident(
            `LineSegmentSketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    CurryType,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Box,
                ),
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `concave_components`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Box,
                ),
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `L`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `ilen`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Literal(
            LiteralData::Integer(
                UnspecifiedRegular(
                    0,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Literal(
            LiteralData::Integer(
                UnspecifiedRegular(
                    1,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                While,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Minus,
            ),
        ),
        TokenData::Ident(
            `L`,
        ),
        TokenData::WordOpr(
            WordOpr::And,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Ident(
            `is_convex`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Suffix(
                    Decr,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `ccv_start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                While,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `ccv_start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    Closed(
                        Add,
                    ),
                ),
            ),
        ),
        TokenData::Ident(
            `L`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                While,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    Comparison(
                        Leq,
                    ),
                ),
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    Closed(
                        Add,
                    ),
                ),
            ),
        ),
        TokenData::Ident(
            `L`,
        ),
        TokenData::WordOpr(
            WordOpr::And,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Ident(
            `is_convex`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Suffix(
                    Incr,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                If,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    Closed(
                        Add,
                    ),
                ),
            ),
        ),
        TokenData::Literal(
            LiteralData::Integer(
                UnspecifiedRegular(
                    1,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `concave_components`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `push`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `cyclic_slice_leashed`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    Closed(
                        Add,
                    ),
                ),
            ),
        ),
        TokenData::Literal(
            LiteralData::Integer(
                UnspecifiedRegular(
                    1,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Return,
            ),
        ),
        TokenData::Ident(
            `concave_components`,
        ),
    ],
    token_group_starts: [
        TokenGroupStart(
            TokenIdx(
                1,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                7,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                15,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                23,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                29,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                33,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                49,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                54,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                61,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                68,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                71,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                76,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                79,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                84,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                97,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                102,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                107,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                120,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                128,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                140,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                159,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                170,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                179,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                184,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                187,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                189,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                194,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                199,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                219,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                238,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                251,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                261,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                264,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                266,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                271,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                284,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                291,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                298,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                305,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                312,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                331,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                342,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                352,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                362,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                372,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                382,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                400,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                405,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                417,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                424,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                456,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                463,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                477,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                484,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                498,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                505,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                514,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                521,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                533,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                540,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                552,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                566,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                576,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                586,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                591,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                596,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                610,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                612,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                616,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                623,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                638,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                640,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                647,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                667,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                670,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                675,
            ),
        ),
    ],
    indents: [
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        4,
        8,
        0,
        4,
        8,
        4,
        8,
        4,
        8,
        8,
        8,
        8,
        8,
        12,
        12,
        12,
        16,
        8,
        4,
        8,
        8,
        8,
        12,
        12,
        12,
        8,
        4,
        8,
        8,
        8,
        8,
        8,
        8,
        12,
        12,
        12,
        12,
        12,
        8,
        4,
        8,
        4,
        8,
        4,
        8,
        4,
        8,
        4,
        8,
        4,
        8,
        4,
        8,
        0,
        4,
        4,
        4,
        4,
        4,
        8,
        4,
        4,
        8,
        12,
        8,
        12,
        8,
        8,
        4,
    ],
}