Ok(
    TokenSheetData {
        tokens: [
            TokenData::Keyword(
                Keyword::Mod,
            ),
            TokenData::Ident(
                `connected_component`,
            ),
            TokenData::Keyword(
                Keyword::Mod,
            ),
            TokenData::Ident(
                `raw_contour`,
            ),
            TokenData::Keyword(
                Keyword::Mod,
            ),
            TokenData::Ident(
                `geom2d`,
            ),
            TokenData::Keyword(
                Keyword::Mod,
            ),
            TokenData::Ident(
                `line_segment_sketch`,
            ),
            TokenData::Keyword(
                Keyword::Mod,
            ),
            TokenData::Ident(
                `fermi`,
            ),
            TokenData::Keyword(
                Keyword::Mod,
            ),
            TokenData::Ident(
                `digits`,
            ),
            TokenData::Keyword(
                Keyword::Mod,
            ),
            TokenData::Ident(
                `major`,
            ),
            TokenData::Keyword(
                Keyword::Use,
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    SelfValue,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Ident(
                `major`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Star,
                ),
            ),
            TokenData::Keyword(
                Keyword::Use,
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    SelfValue,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Ident(
                `digits`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Star,
                ),
            ),
            TokenData::Keyword(
                Keyword::Use,
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    SelfValue,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Ident(
                `fermi`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Star,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Use,
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    SelfValue,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Ident(
                `raw_contour`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Star,
                ),
            ),
            TokenData::Keyword(
                Keyword::Use,
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    SelfValue,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Ident(
                `line_segment_sketch`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Star,
                ),
            ),
            TokenData::Keyword(
                Keyword::Use,
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    SelfValue,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Ident(
                `connected_component`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Star,
                ),
            ),
            TokenData::Keyword(
                Keyword::Use,
            ),
            TokenData::Ident(
                `malamute`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Star,
                ),
            ),
            TokenData::Keyword(
                Keyword::Use,
            ),
            TokenData::Ident(
                `mnist`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Star,
                ),
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Val,
                ),
            ),
            TokenData::Ident(
                `main`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Colon,
                ),
            ),
            TokenData::Ident(
                `Class`,
            ),
            TokenData::Ident(
                `MnistLabel`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Eq,
                ),
            ),
            TokenData::Ident(
                `is_one`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Question,
                ),
            ),
            TokenData::Ident(
                `is_six`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Question,
                ),
            ),
            TokenData::Ident(
                `is_zero`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Question,
                ),
            ),
            TokenData::Ident(
                `is_seven`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Question,
                ),
            ),
            TokenData::Ident(
                `is_eight`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Question,
                ),
            ),
            TokenData::Ident(
                `is_three`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Question,
                ),
            ),
            TokenData::Ident(
                `is_nine`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Question,
                ),
            ),
            TokenData::Ident(
                `is_five`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Question,
                ),
            ),
            TokenData::Ident(
                `is_two`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Question,
                ),
            ),
            TokenData::Ident(
                `Class`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Ident(
                `Known`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Ident(
                `MnistLabel`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Ident(
                `Four`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
        ],
        token_group_starts: [
            TokenGroupStart(
                TokenIdx(
                    1,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    3,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    5,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    7,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    9,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    11,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    13,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    15,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    21,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    27,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    34,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    40,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    46,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    52,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    56,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    60,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    66,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    68,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    70,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    72,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    74,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    76,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    78,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    80,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    82,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    84,
                ),
            ),
        ],
        indents: [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
        ],
    },
)