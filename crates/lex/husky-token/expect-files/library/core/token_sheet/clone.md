Ok(
    TokenSheetData {
        tokens: [
            Token::Keyword(
                Keyword::Use,
            ),
            Token::Keyword(
                Keyword::Pronoun(
                    Crate,
                ),
            ),
            Token::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            Token::Punctuation(
                Punctuation(
                    PunctuationMapped::Star,
                ),
            ),
            Token::Keyword(
                Keyword::Pub,
            ),
            Token::Keyword(
                Keyword::Trait,
            ),
            Token::Ident(
                `Clone`,
            ),
            Token::Punctuation(
                Punctuation(
                    PunctuationMapped::Colon,
                ),
            ),
            Token::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            Token::Ident(
                `clone`,
            ),
            Token::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            Token::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            Token::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            Token::Keyword(
                Keyword::Pronoun(
                    SelfType,
                ),
            ),
            Token::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            Token::Keyword(
                Keyword::Impl,
            ),
            Token::Ident(
                `Clone`,
            ),
            Token::Keyword(
                Keyword::Connection(
                    For,
                ),
            ),
            Token::Punctuation(
                Punctuation(
                    PunctuationMapped::At,
                ),
            ),
            Token::Ident(
                `derive`,
            ),
            Token::Ident(
                `_`,
            ),
            Token::Punctuation(
                Punctuation(
                    PunctuationMapped::Colon,
                ),
            ),
            Token::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            Token::Ident(
                `clone`,
            ),
            Token::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            Token::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            Token::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            Token::Keyword(
                Keyword::Pronoun(
                    SelfType,
                ),
            ),
            Token::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
        ],
        token_group_bases: [
            TokenGroupStartingTokenIdx(
                TokenIdx(
                    1,
                ),
            ),
            TokenGroupStartingTokenIdx(
                TokenIdx(
                    5,
                ),
            ),
            TokenGroupStartingTokenIdx(
                TokenIdx(
                    9,
                ),
            ),
            TokenGroupStartingTokenIdx(
                TokenIdx(
                    16,
                ),
            ),
            TokenGroupStartingTokenIdx(
                TokenIdx(
                    23,
                ),
            ),
        ],
        indents: [
            0,
            0,
            4,
            0,
            4,
        ],
    },
)