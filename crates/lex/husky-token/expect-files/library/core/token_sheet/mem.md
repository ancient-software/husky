Ok(
    TokenSheetData {
        tokens: [
            TokenData::Keyword(
                Keyword::Use,
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    Crate,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Star,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::TypeEntity(
                    Extern,
                ),
            ),
            TokenData::Ident(
                `Ref`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::LaOrLt,
                ),
            ),
            TokenData::Keyword(
                Keyword::Modifier(
                    Covariant,
                ),
            ),
            TokenData::Label(
                `'a`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Comma,
                ),
            ),
            TokenData::Keyword(
                Keyword::Modifier(
                    Covariant,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::RaOrGt,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::TypeEntity(
                    Extern,
                ),
            ),
            TokenData::Ident(
                `RefMut`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::LaOrLt,
                ),
            ),
            TokenData::Keyword(
                Keyword::Modifier(
                    Covariant,
                ),
            ),
            TokenData::Label(
                `'a`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Comma,
                ),
            ),
            TokenData::Keyword(
                Keyword::Modifier(
                    Invariant,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::RaOrGt,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::TypeEntity(
                    Extern,
                ),
            ),
            TokenData::Ident(
                `Leash`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::LaOrLt,
                ),
            ),
            TokenData::Keyword(
                Keyword::Modifier(
                    Covariant,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::RaOrGt,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Impl,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::LaOrLt,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::RaOrGt,
                ),
            ),
            TokenData::Ident(
                `Copy`,
            ),
            TokenData::Keyword(
                Keyword::Connection(
                    For,
                ),
            ),
            TokenData::Ident(
                `Leash`,
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::TypeEntity(
                    Extern,
                ),
            ),
            TokenData::Ident(
                `At`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::LaOrLt,
                ),
            ),
            TokenData::Label(
                `'Î±`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Comma,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::RaOrGt,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
        ],
        token_group_starts: [
            TokenGroupStart(
                TokenIdx(
                    1,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    5,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    16,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    27,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    35,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    44,
                ),
            ),
        ],
        indents: [
            0,
            0,
            0,
            0,
            0,
            0,
        ],
    },
)