```rust
TokenSheetData {
    tokens: [
        TokenData::Keyword(
            Keyword::Use,
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                Crate,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Star,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::Add",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `Add`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Type,
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `add`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `other`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfType,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::AddAssign",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `AddAssign`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Type,
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `add`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `other`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfType,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::BitAnd",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `BitAnd`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Type,
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `bitand`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfType,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::BitAndAssign",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `BitAndAssign`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `bitand_assign`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::BitOr",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `BitOr`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Type,
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `bitor`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfType,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::BitOrAssign",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `BitOrAssign`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `bitor_assign`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::BitXor",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `BitXor`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Type,
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `bitxor`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfType,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::BitXorAssign",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `BitXorAssign`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `bitxor_assign`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::Div",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `Div`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Type,
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `div`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfType,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::DivAssign",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `DivAssign`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `div_assign`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `IntIndex`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Type,
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::Mul",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `Mul`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Type,
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `mul`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfType,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::MulAssign",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `MulAssign`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `mul_assign`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::Neg",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `Neg`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Type,
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `neg`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfType,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::Not",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `Not`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Type,
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `not`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfType,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `rust`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::String(
                StringLiteralTokenData {
                    data: "std::ops::Sub",
                },
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `Sub`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Type,
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `sub`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `other`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `Rhs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfType,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Trait,
        ),
        TokenData::Ident(
            `Unveil`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `T`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Keyword(
            Keyword::Connection(
                Extends,
            ),
        ),
        TokenData::Ident(
            `Sized`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Type,
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Static,
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `unveil`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `t`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `T`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `ControlFlow`,
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfType,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfType,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `Output`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Semicolon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::TypeEntity(
                Enum,
            ),
        ),
        TokenData::Ident(
            `ControlFlow`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `B`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `C`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Vert,
            ),
        ),
        TokenData::Ident(
            `Continue`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `C`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Vert,
            ),
        ),
        TokenData::Ident(
            `Break`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `B`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
    ],
    token_verses: TokenVerses {
        main_sequence: MainTokenVerseSequence {
            verses_data: [
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            1,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            5,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            12,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            19,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            22,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            34,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            41,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            48,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            51,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            63,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            70,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            77,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            80,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            92,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            99,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            106,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            117,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            124,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            131,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            134,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            146,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            153,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            160,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            171,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            178,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            185,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            188,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            200,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            207,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            214,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            225,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            232,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            239,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            242,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            254,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            261,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            268,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            279,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            283,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            286,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            293,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            300,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            303,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            315,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            322,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            329,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            340,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            347,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            351,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            354,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            364,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            371,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            375,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            378,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            388,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            395,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            402,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            405,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            417,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            426,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            429,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            444,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            452,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            457,
                        ),
                    ),
                    indent: 0,
                },
            ],
        },
        nested_sequences: [],
    },
}
```