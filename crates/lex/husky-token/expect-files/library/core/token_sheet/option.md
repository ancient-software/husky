TokenSheetData {
    tokens: [
        TokenData::Keyword(
            Keyword::Use,
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                Crate,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    ScopeResolution,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Star,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Use,
        ),
        TokenData::Ident(
            `Option`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    ScopeResolution,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Star,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Pound,
            ),
        ),
        TokenData::Ident(
            `derive`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `Debug`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `PartialEq`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `Eq`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `Clone`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `Copy`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::TypeEntity(
                Enum,
            ),
        ),
        TokenData::Ident(
            `Option`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `T`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Vertical,
            ),
        ),
        TokenData::Ident(
            `Some`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Par,
                ),
            ),
        ),
        TokenData::Ident(
            `T`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Vertical,
            ),
        ),
        TokenData::Ident(
            `None`,
        ),
    ],
    token_group_starts: [
        TokenGroupStart(
            TokenIdx(
                1,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                5,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                10,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                23,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                29,
            ),
        ),
        TokenGroupStart(
            TokenIdx(
                34,
            ),
        ),
    ],
    indents: [
        0,
        0,
        0,
        0,
        0,
        0,
    ],
}