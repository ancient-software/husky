Ok(
    TokenSheetData {
        tokens: [
            TokenData::Keyword(
                Keyword::Use,
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    Crate,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Star,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::TypeEntity(
                    Extern,
                ),
            ),
            TokenData::Ident(
                `Slice`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::LaOrLt,
                ),
            ),
            TokenData::Keyword(
                Keyword::Modifier(
                    Covariant,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::RaOrGt,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Impl,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::LaOrLt,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::RaOrGt,
                ),
            ),
            TokenData::Ident(
                `Slice`,
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Colon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `len`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            TokenData::Ident(
                `usize`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `swap`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ambersand,
                ),
            ),
            TokenData::Keyword(
                Keyword::Modifier(
                    Mut,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    SelfValue,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Comma,
                ),
            ),
            TokenData::Ident(
                `a`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Colon,
                ),
            ),
            TokenData::Ident(
                `usize`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Comma,
                ),
            ),
            TokenData::Ident(
                `b`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Colon,
                ),
            ),
            TokenData::Ident(
                `usize`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::At,
                ),
            ),
            TokenData::Ident(
                `derive`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Ident(
                `Debug`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Comma,
                ),
            ),
            TokenData::Ident(
                `Visualize`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::TypeEntity(
                    Extern,
                ),
            ),
            TokenData::Ident(
                `CyclicSlice`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::LaOrLt,
                ),
            ),
            TokenData::Keyword(
                Keyword::Modifier(
                    Covariant,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::RaOrGt,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Impl,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::LaOrLt,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::RaOrGt,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    Crate,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Ident(
                `ops`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Ident(
                `IntIndex`,
            ),
            TokenData::Keyword(
                Keyword::Connection(
                    For,
                ),
            ),
            TokenData::Ident(
                `CyclicSlice`,
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Colon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Type,
                ),
            ),
            TokenData::Ident(
                `Output`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Eq,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Keyword(
                Keyword::Impl,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::LaOrLt,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::RaOrGt,
                ),
            ),
            TokenData::Ident(
                `CyclicSlice`,
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Colon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `ilen`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            TokenData::Ident(
                `i32`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `start`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            TokenData::Ident(
                `i32`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `end`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            TokenData::Ident(
                `i32`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `first`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Question,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Tilde,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `last`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Question,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Tilde,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
        ],
        token_group_starts: [
            TokenGroupStart(
                TokenIdx(
                    1,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    5,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    13,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    20,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    28,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    45,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    52,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    60,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    73,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    77,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    84,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    92,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    100,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    108,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    118,
                ),
            ),
        ],
        indents: [
            0,
            0,
            0,
            4,
            4,
            0,
            0,
            0,
            4,
            0,
            4,
            4,
            4,
            4,
            4,
        ],
    },
)