Ok(
    TokenSheetData {
        tokens: [
            TokenData::Keyword(
                Keyword::Use,
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    Crate,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        ScopeResolution,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Star,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Pound,
                ),
            ),
            TokenData::Ident(
                `derive`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Ident(
                `Debug`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Comma,
                ),
            ),
            TokenData::Ident(
                `Clone`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Comma,
                ),
            ),
            TokenData::Ident(
                `Visualize`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::TypeEntity(
                    Extern,
                ),
            ),
            TokenData::Ident(
                `Vec`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::LaOrLt,
                ),
            ),
            TokenData::Keyword(
                Keyword::Modifier(
                    Covariant,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::RaOrGt,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Impl,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::LaOrLt,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::RaOrGt,
                ),
            ),
            TokenData::Ident(
                `Vec`,
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Colon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `ilen`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            TokenData::Ident(
                `i32`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `push`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ambersand,
                ),
            ),
            TokenData::Keyword(
                Keyword::Modifier(
                    Mut,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    SelfValue,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Comma,
                ),
            ),
            TokenData::Ident(
                `e`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Colon,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `first`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            TokenData::Ident(
                `Option`,
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `last`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            TokenData::Ident(
                `Option`,
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `pop`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ambersand,
                ),
            ),
            TokenData::Keyword(
                Keyword::Modifier(
                    Mut,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    SelfValue,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            TokenData::Ident(
                `Option`,
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `collect_leashes`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Tilde,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    SelfValue,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Box,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Box,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Tilde,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `cyclic_slice_leashed`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Tilde,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    SelfValue,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Comma,
                ),
            ),
            TokenData::Ident(
                `start`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Colon,
                ),
            ),
            TokenData::Ident(
                `i32`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Comma,
                ),
            ),
            TokenData::Ident(
                `end`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Colon,
                ),
            ),
            TokenData::Ident(
                `i32`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Tilde,
                ),
            ),
            TokenData::Ident(
                `CyclicSlice`,
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pub,
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Ident(
                `pop_with_largest_opt_f32`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ambersand,
                ),
            ),
            TokenData::Keyword(
                Keyword::Modifier(
                    Mut,
                ),
            ),
            TokenData::Keyword(
                Keyword::Pronoun(
                    SelfValue,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Comma,
                ),
            ),
            TokenData::Ident(
                `f`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Colon,
                ),
            ),
            TokenData::Keyword(
                Keyword::Fugitive(
                    Fn,
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Bra(
                        Par,
                    ),
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Question,
                ),
            ),
            TokenData::Ident(
                `f32`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Ket(
                        Par,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Binary(
                        Curry,
                    ),
                ),
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Question,
                ),
            ),
            TokenData::Ident(
                `E`,
            ),
            TokenData::Punctuation(
                Punctuation(
                    PunctuationMapped::Semicolon,
                ),
            ),
        ],
        token_group_starts: [
            TokenGroupStart(
                TokenIdx(
                    1,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    5,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    14,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    22,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    29,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    37,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    50,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    59,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    68,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    80,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    93,
                ),
            ),
            TokenGroupStart(
                TokenIdx(
                    113,
                ),
            ),
        ],
        indents: [
            0,
            0,
            0,
            0,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
        ],
    },
)