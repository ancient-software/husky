%:
\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}
\usepackage{diagbox}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{enumerate}
\theoremstyle{definition}
\newtheorem*{defn}{Definition}
\newtheorem*{prop}{Proposition}
\newtheorem*{eg}{Example}
\newtheorem*{thm}{Theorem}
\newtheorem*{corol}{Corollary}
\newtheorem{ex}{Exercise}[section]
{\theoremstyle{plain}
\newtheorem*{rmk}{Remark}
\newtheorem*{rmks}{Remarks}
\newtheorem*{lt}{Last time}
}
\newtheorem*{lem}{Lemma}
\usepackage{color}
\usepackage{CJK}
\title{Lecture Note on the Husky Project}
\author{Xiyu Zhai}
\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle
\tableofcontents
\section{Introduction}

The husky project (\url{https://github.com/ancient-software/husky}) is currently a project in computer vision, which starts five years ago even before my PhD.

(Pdf of lecture note: \url{https://github.com/ancient-software/husky/blob/main/sparks/impress/lecture1.pdf})

(Latex Source of lecture note: \url{https://github.com/ancient-software/husky/blob/main/sparks/impress/lecture1.tex})

Warning: this is work in progress. It shall take a long time to complete this note.

\subsection{Composition}

It comprises mainly of two parts:
\begin{enumerate}[(1)]
	\item a new machine learning framework with new algorithms and ways of feature constructions that are geometrically more appropriate for shape analysis;

	\begin{rmk}
	todo: explain what is geometrically appropriate
	\end{rmk}
	\item a new programming language that is critical for interactively implementing and improving efficient and fully interpretable models.

	\begin{rmk}
		PL is generalizable to other domains, like NLP, Theorem Proving, Robotics, RL, Computer Graphics, etc. I'm in the way of overhauling the type system to introduce Monad for NLP and Robotics and RL and Prop for theorem proving.

		As a result, this PL is an extremely ambitious project that must have all good things from languages in different domains, C++/Rust/Zig from system level programming
	\end{rmk}
\end{enumerate}

\begin{rmk}
	todo: explain why this is difficult for previous experts in the field.
\end{rmk}

\subsection{Difference}

\paragraph{Traditional Computer Vision.} 
Handcrafted feature descriptors such as SIFT and SURF are fed to traditional
machine learning classification algorithms such as Support Vector Machines and k-Nearest Neighbours to solve the aforementioned CV problems.

Computation: matrix (mostly)

Biggest problem: doesn't work well for large datasets.


\paragraph{Deep Learning.}  End to end training.

Computation: matrix

Biggest problem: doesn't explain well, totally not scientific.

\paragraph{Husky.} Interactively construct features that is interpretable and efficient, first purely by hand then automate more and more in the process. Feature is no longer just a map from input to a vector space, it's a map from input to a type, which encodes information in an domain specific, interpretable and efficient way.

For image classification, the training process is replaced by the following iterative developing process (with labeling being part of it)

\begin{itemize}
	\item Replace the goal of finding an all-powerful classifier by finding for each class a one-vs-all classifier.

	\begin{rmk}
		When the number of classes is really large, we will use LSH(locally sensitive hashing)-like schemes. But for imagenet, this is not necessary.
	\end{rmk}
	\item For each class, try to represent the one-vs-all classifier by a cascade, i.e. a sequence  of partial classifiers together with a one-vs-all classifier in the end.

	todo: explain partial classifier
	\item Partial classifiers are first constructed by hand interactively. Constantly interact with the debugger.
\end{itemize}

This process maps to a drastically different set of requirements on development tools:
\begin{itemize}
	\item Require the ability to easily write system level programming because we are not using matrices

	\begin{rmk}
		This rules out python.
	\end{rmk}
	\item Incrementally compute the features in a functional way, i.e. instant response even for imagenent

	\begin{rmk}
		This rules out every existing language, especially those requiring long compilation time like C++/Rust/Zig. But python and julia are kindof okay because they can run in a notebook environment. The only problem is that notebook is procedural, not functional, can't scale every well.
	\end{rmk}
	\item One-click visualization of one or more features (possibly restricted to a branch or a datapoint)

	\begin{rmk}
		This rules out every existing language.
	\end{rmk}
	\item Higher order functions for automation: one expr for constructing and training a model

	\begin{rmk}
		This rules out every existing language.
	\end{rmk}
	\item Automatic memory

	\begin{rmk}
		This rules out every existing language except Rust.
	\end{rmk}
	\item Automatic lazy value cache management across domains

	\begin{rmk}
		This rules out every existing language. Haskell has features that sounds similar, but isn't good enough.
	\end{rmk}
	\item Rigorous type system to avoid distracting programmer from the task at hand

	\begin{rmk}
		This rules out python.
	\end{rmk}
\end{itemize}


So that's why I feel it necessary to develop a new language.

\subsection{Future}


The future is going to be like:

\begin{itemize}
	\item in two years, imagenet is done in husky by myself, totally interpretable and as accurate and 100 times faster for inference; the development only requires a moderate computer and it doesn't need GPU for training and inference.

	Rougly speaking, it's going to be like:
		\begin{itemize}
			\item 4 months recognise husky
			\item 4 months recognise 9 more classes
			\item 4 months recognise 90 more with automation
			\item 4 months recognise 900 more with much better automation
			\item 8 months for improvement on all fronts
		\end{itemize}
	\item gains popularity because husky doesn't require GPU and is a new programming language that is much more easier to make right than python, and can publish papers because people are convinced.
	\item husky applies to Computer Graphics(GAN, etcs.), RL, Robotics
	\item I will raise funding for NLP and theorem proving, in 5 to 30 years will replace large language models (transformers, etc)
\end{itemize}

\subsection{Now}

The current state of the project is
\begin{itemize}
	\item theoretical stuffs are clear (nothing changes significantly from two years ago); mathematically I'm fully convinced that things will work. However, to be convincing for other people with less mathematical maturity, this is probably not enough. But it doesn't really matter because I'm going to be the one who can make essential contribution to the project due to the complexity of things.
	\item a minimal (barely) working version of language is there, for which I wrote many code in the last two years.
	\begin{itemize}
		\item first year work C++
		\item second year Rust
	\end{itemize}
	\item have only spent very limited time in actually making it work
	\begin{itemize}
		\item using the C++ version a model for mnist which is 97\% accuracy for half of the data 
		\item Mnist using the latest version in progress. Not in a hurry, because people aren't convinced by Mnist no matter how good the result is. Will do it when I have the mood.
		\item Imagenet in progress, 
	\end{itemize}
\begin{rmk}
	todo: explain what percentage means
\end{rmk}
\end{itemize}

\subsection{Past}

It initially is very different, the path is
\begin{itemize}
	\item deep learning theory
	\item algorithm + machine learning
	\item geometric algorithm
	\item programming language
\end{itemize}

\section{Inference Process for Image Classification}
\subsection{Mnist}
\subsection{Imagenet(tentative)}

\section{Theoretical Framework: Nontrival Machine Learning}

\begin{eg}
	[Linear Classification]
\end{eg}
\end{document}